{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarefa08.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNxtOopDgDhDmFN1MXSlMAq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HenriqueColombari/Processamento_Imagens/blob/main/Tarefa08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUPALhFV1-_-"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpl7d0LjzNAt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5859c5d-c121-4be4-df62-369792a1767e"
      },
      "source": [
        "import os #para trabalhar com os diret칩rios\n",
        "import csv #salvar os resultados dos exercicios 1 e 2\n",
        "import shutil\n",
        "import cv2 as cv #processamento de imagens\n",
        "import numpy as np #matem치ticas gerais\n",
        "import matplotlib.pyplot as plt #plots gr치ficos\n",
        "\n",
        "from os import walk\n",
        "from os import listdir #usado com o walk para retornar a lista com o nome de todos os arquivos em um diret칩rio\n",
        "from pandas import crosstab #retornar a matriz com os resultados do MLP\n",
        "from google.colab import drive #comunica칞칚o com o google drive\n",
        "from os.path import isfile, join\n",
        "from sklearn import preprocessing #para normaliza칞칚o\n",
        "from sklearn.neural_network import MLPClassifier #rede neural utilizada na classifica칞칚o\n",
        "from sklearn.model_selection import train_test_split #divis칚o do dataset em treino e teste\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg57LUyd7TFw"
      },
      "source": [
        "#Carregando o Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_A-QKFz97blM",
        "outputId": "c1fa0779-1d7d-44f0-d803-a61a1ca6bbbc"
      },
      "source": [
        "path = \"drive//MyDrive//Processamento de Imagem//frutas_dataset//images\"        #path para os arquivos carregados no drive\n",
        "\n",
        "\n",
        "\n",
        "all_files = []                                                                  #listagem de todas as imagens dentro do diret칩rio \n",
        "for (dirpath, dirnames, filenames) in walk(path):\n",
        "  all_files.extend(filenames)\n",
        "\n",
        "i = 0\n",
        "images_load = []                                                                #lista que guaradar치 as imagens \n",
        "print(\"Quantidade de imagens: \" + str(len(all_files)))\n",
        "print(\"Carregando, isso pode demorar um pouco 游땞\")\n",
        "while i < len(all_files):                                                       #loop para tratar e carregar todos os 300 arquivos\n",
        "  temp = cv.imread(path + \"//\" +all_files[i], 0)\n",
        "\n",
        "  kernel = np.ones((3,3),np.uint8) \n",
        "  temp = cv.morphologyEx(temp, cv.MORPH_OPEN, kernel, iterations = 2)           #filtragem de ruidos\n",
        "\n",
        "  temp = cv.dilate(temp, kernel,iterations=1)                                   #opera칞칚o de dilata칞칚o = preencher pequenos espa칞os na imagem\n",
        "\n",
        "  temp = cv.resize(temp, (30, 30), interpolation = cv.INTER_AREA)               #redimensionar as imagens para 30x30\n",
        "\n",
        "  for lin in range(temp.shape[0]):                                              #loop para converter em preto/branco   \n",
        "    for col in range(temp.shape[1]):\n",
        "    \n",
        "      pixel = temp.item(lin,col)\n",
        "      if ( pixel > 127):\n",
        "        temp.itemset( (lin,col), 0)\n",
        "      else:\n",
        "        temp.itemset( (lin,col), 255)\n",
        "  images_load.append([int(all_files[i][0:3]), temp])                            #adicionar a imagem a lista de imagens carregadas\n",
        "\n",
        "\n",
        "  i = i + 1\n",
        "\n",
        "images_load.sort()                                                              #ordenar a lista com as imagens\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.subplot(121), plt.imshow(images_load[0][1],cmap='binary'), plt.axis(\"off\")\n",
        "plt.subplot(122), plt.imshow(images_load[-1][1],cmap='binary'), plt.axis(\"off\")\n",
        "plt.show()                                                                      #plot da primeira e da ultima imagem do dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cec642973328>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mall_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m                                                                  \u001b[0;31m#listagem de todas as imagens dentro do diret칩rio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdirpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mall_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'walk' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdHYTu7b2G87"
      },
      "source": [
        "#Exerc칤cio 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbPAjIXO2NvS",
        "outputId": "8292faf2-941f-4979-993c-0c6ebdea9644"
      },
      "source": [
        "i = 0\n",
        "data = []                                                                       #lista que guardar치 os dados que ser칚o utilizados no MLP\n",
        "while i < len(images_load):\n",
        "  data.append([images_load[i][0]])                                              #guarda o indice  \n",
        "  i = i + 1\n",
        "\n",
        "\n",
        "i = 0\n",
        "while i < len(images_load):                                                     #loop para gerar os descritores de borda de cade imagem                                        \n",
        "  contours, hierarchy = cv.findContours(images_load[i][1], cv.RETR_TREE,\n",
        "                                        cv.CHAIN_APPROX_NONE)\n",
        "  perimetro = cv.arcLength(contours[0], True)                                   #perimetro\n",
        "\n",
        "  diametro = np.sqrt(4*cv.contourArea(contours[0])/np.pi)                       #diametro\n",
        "  \n",
        "  data[i].append(perimetro)\n",
        "  data[i].append(diametro)\n",
        "\n",
        "  i = i + 1\n",
        "\n",
        "i = 0\n",
        "while i < len(data):                                                            #remover uma das colunas, caso a imagem n칚o tenha gerado perimetro ou diametro\n",
        "  if(data[i][1] == 0 or data[i][2] == 0):\n",
        "    data.pop(i)\n",
        "    images_load.pop(i)\n",
        "    i = i - 1\n",
        "  i = i + 1\n",
        "\n",
        "print(\"Quanditade de imagens com dados v치lidos:\", str(len(data)))\n",
        "\n",
        "with open('exercicio1.csv', 'w') as myfile:                                     #gera um arquivo em formato csv para armazenar os dados gerados\n",
        "    wr = csv.writer(myfile, dialect='excel')                                    #o arquivo gerado fica disponivel temporariamente nos arquivos do colab\n",
        "    wr.writerow(['Index', 'Perimetro', 'Diametro'])\n",
        "    i = 0\n",
        "    while i < len(data):\n",
        "      wr.writerow(data[i])\n",
        "      i = i + 1 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quanditade de imagens com dados v치lidos: 298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhVqFBUT5AW2"
      },
      "source": [
        "#Exerc칤cio 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtfH13Rf5Dmp",
        "outputId": "63270c6c-b5c6-4823-a4a0-f2437c5253ab"
      },
      "source": [
        "i = 0\n",
        "check_data = True\n",
        "while i < len(images_load):                                                     #loop para gerar os descritores de regi칚o\n",
        "  \n",
        "  area = cv.countNonZero(images_load[i][1])                                     #area\n",
        "\n",
        "  \n",
        "  contours, hierarchy = cv.findContours(images_load[i][1], cv.RETR_TREE, \n",
        "                                        cv.CHAIN_APPROX_NONE)\n",
        "  perimetro = cv.arcLength(contours[0], True)\n",
        "  compacidade = np.square(perimetro)/area                                       # Compacidade\n",
        "\n",
        "  \n",
        "  (x,y), (eixoMenor,eixoMaior),angulo = cv.fitEllipse(contours[0])\n",
        "  excentricidade = (eixoMaior/eixoMenor)                                        #excentricidade\n",
        "\n",
        "  retangularidade = area/(eixoMaior*eixoMenor)                                  #retangularidade\n",
        "\n",
        "  area_obj = cv.contourArea(contours[0])\n",
        "  area_fechoconvexo = cv.contourArea( cv.convexHull(contours[0]))\n",
        "  solidez = area_obj/area_fechoconvexo                                          #solidez\n",
        "  \n",
        "  if(len(data[i]) == 3):                                                        #antes de rodar o exercicio 2 novamente, deve-se executar o exercicio 1\n",
        "    data[i].append(area)\n",
        "    data[i].append(compacidade)\n",
        "    data[i].append(excentricidade)\n",
        "    data[i].append(solidez)\n",
        "    data[i].append(retangularidade)                                             #append das novas features\n",
        "  else:\n",
        "    check_data = False\n",
        "\n",
        "  i = i + 1\n",
        "\n",
        "\n",
        "if(not check_data):\n",
        "  print(\"Execute o exerc칤cio 1 novamente para limpar os dados\")\n",
        "\n",
        "\n",
        "i = 0\n",
        "while i < len(data):                                                            #remover uma das colunas, caso a imagem n칚o tenha gerado descritores de regi칚o v치lidos\n",
        "  if(data[i][3] == 0 or data[i][4] == 0):\n",
        "    data.pop(i)\n",
        "    i = i - 1\n",
        "  i = i + 1\n",
        "\n",
        "print(\"Quanditade de imagens com dados v치lidos:\", str(len(data)))\n",
        "\n",
        "with open('exercicio2.csv', 'w') as myfile:                                     #gera um arquivo em formato csv para armazenar os dados gerados\n",
        "    wr = csv.writer(myfile, dialect='excel')\n",
        "    wr.writerow(['Index', 'Perimetro', 'Diametro', 'Area', 'Compacidade', \n",
        "                 'Excentricidade', 'Solidez', 'Retangularidade'])\n",
        "    i = 0\n",
        "    while i < len(data):\n",
        "      wr.writerow(data[i])\n",
        "      i = i + 1 \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quanditade de imagens com dados v치lidos: 298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UFiFWQc-8RZ"
      },
      "source": [
        "#Exercicio 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pY1fsSpAL0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd7945fc-aafb-4eb7-9335-7f2e88ceff7e"
      },
      "source": [
        "temp_data = data[:]\n",
        "\n",
        "i = 0\n",
        "frutas = []\n",
        "output_esperado = []\n",
        "while i < len(temp_data):                                                       #loop para nomear as frutas de acordo com a classifica칞칚o passada\n",
        "  if(temp_data[i][0] <= 30):\n",
        "    output_esperado.append('mac')\n",
        "  elif(temp_data[i][0] <= 60):\n",
        "    output_esperado.append('abc')\n",
        "  elif(temp_data[i][0] <= 90):\n",
        "    output_esperado.append('bnn')\n",
        "  elif(temp_data[i][0] <= 120):\n",
        "    output_esperado.append('psg')\n",
        "  elif(temp_data[i][0] <= 150):\n",
        "    output_esperado.append('ptg')\n",
        "  elif(temp_data[i][0] <= 180):\n",
        "    output_esperado.append('lrj')\n",
        "  elif(temp_data[i][0] <= 210):\n",
        "    output_esperado.append('mrg')\n",
        "  elif(temp_data[i][0] <= 240):\n",
        "    output_esperado.append('per')\n",
        "  elif(temp_data[i][0] <= 270):\n",
        "    output_esperado.append('lim')\n",
        "  elif(temp_data[i][0] <= 300):\n",
        "    output_esperado.append('uva')\n",
        "\n",
        "\n",
        "  frutas.append(temp_data[i][1:])\n",
        "  i = i + 1\n",
        "\n",
        "\n",
        "frutas = preprocessing.normalize(frutas)                                        #normaliza칞칚o dos dados para passa-los no MLP\n",
        "\n",
        "\n",
        "#divisao dos dados em treino e teste, 80% e 20%, respectivamente, obteve melhores resultados\n",
        "frutas_train_x, frutas_test_x, frutas_train_y, frutas_test_y = train_test_split(frutas, output_esperado, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "clf = MLPClassifier(max_iter=4000).fit(frutas_train_x, frutas_train_y)          #cria칞칚o do modelo do MLP\n",
        "\n",
        "frutas_test_y = np.array(frutas_test_y)\n",
        "\n",
        "print(\"Precis칚o:\",  str(clf.score(frutas_test_x, frutas_test_y)))               #essa previs칚o foi de uma boa rodada, a m칠dia foi de 75% 游땎\n",
        "\n",
        "#matriz gerada com a predicao e a classe verdadeira\n",
        "print(crosstab(frutas_test_y, clf.predict(frutas_test_x), rownames=['true'], colnames=['predicted'])) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precis칚o: 0.8666666666666667\n",
            "predicted  abc  bnn  lim  lrj  mac  mrg  per  psg  ptg  uva\n",
            "true                                                       \n",
            "abc          5    0    0    0    0    0    0    0    0    0\n",
            "bnn          0    9    0    0    0    0    0    0    0    0\n",
            "lim          0    0    4    0    0    0    0    0    0    0\n",
            "lrj          0    0    0    4    0    2    0    0    0    0\n",
            "mac          0    0    0    0    4    0    0    2    0    0\n",
            "mrg          0    0    0    0    0    5    1    0    0    0\n",
            "per          0    0    0    0    0    3    2    0    0    0\n",
            "psg          0    0    0    0    0    0    0   10    0    0\n",
            "ptg          0    0    0    0    0    0    0    0    4    0\n",
            "uva          0    0    0    0    0    0    0    0    0    5\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}